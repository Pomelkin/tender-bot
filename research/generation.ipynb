{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SyncPage[Model](data=[Model(id='google/gemma-2-9b-it', created=1726300797, object='model', owned_by='vllm', root='google/gemma-2-9b-it', parent=None, max_model_len=4096, permission=[{'id': 'modelperm-5d1a0caac69d4f0185685fa3291709ee', 'object': 'model_permission', 'created': 1726300797, 'allow_create_engine': False, 'allow_sampling': True, 'allow_logprobs': True, 'allow_search_indices': False, 'allow_view': True, 'allow_fine_tuning': False, 'organization': '*', 'group': None, 'is_blocking': False}])], object='list')\n",
      "SyncPage[Model](data=[Model(id='Qwen/Qwen2-7B-Instruct', created=1726300797, object='model', owned_by='vllm', root='Qwen/Qwen2-7B-Instruct', parent=None, max_model_len=32768, permission=[{'id': 'modelperm-411203e28fb14293950bb7d59e28e3d6', 'object': 'model_permission', 'created': 1726300797, 'allow_create_engine': False, 'allow_sampling': True, 'allow_logprobs': True, 'allow_search_indices': False, 'allow_view': True, 'allow_fine_tuning': False, 'organization': '*', 'group': None, 'is_blocking': False}])], object='list')\n"
     ]
    }
   ],
   "source": [
    "client_gemma = OpenAI(\n",
    "    base_url=\"http://pomelk1n-dev.su:8000/v1\",\n",
    "    api_key=\"token-abc123\",\n",
    ")\n",
    "\n",
    "print(client_gemma.models.list())\n",
    "\n",
    "client_qwen = OpenAI(\n",
    "    base_url=\"http://pomelk1n-dev.su:8001/v1\",\n",
    "    api_key=\"token-abc123\",\n",
    ")\n",
    "\n",
    "print(client_qwen.models.list())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Я — Gemma, большая языковая модель, обученная Google DeepMind. Я могу генерировать текст, переводить языки, писать разные виды творческих контентов и отвечать на ваши вопросы в информативном стиле.\\n\\nЯ все еще учусь и совершенствуюсь, но я всегда рад помочь вам с любыми вопросами или задачами, которые связаны с языком.\\n'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "completion = client_gemma.chat.completions.create(\n",
    "  model=\"google/gemma-2-9b-it\",\n",
    "  messages=[\n",
    "    {\"role\": \"user\", \"content\": \"Ты кто?\"}\n",
    "  ]\n",
    ")\n",
    "\n",
    "completion.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Я - искусственный интеллект, созданный для помощи в ответах на вопросы, предоставления информации и выполнения различных задач. Могу ли я вам помочь с чем-то еще?'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "completion = client_qwen.chat.completions.create(\n",
    "  model=\"Qwen/Qwen2-7B-Instruct\",\n",
    "  messages=[\n",
    "    {\"role\": \"user\", \"content\": \"Ты кто?\"}\n",
    "  ]\n",
    ")\n",
    "\n",
    "completion.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
